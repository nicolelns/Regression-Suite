#! /usr/bin/python
# -*- coding: utf-8 -*-

import os
import sys
import unittest
import time, datetime
import re
import pickle
import Logger			# Logging module (for test results, outputs results to a .txt file)
import cutSoup     		# BeautifulSoup page scraper collects relevant data from qa.nymetro
from selenium import selenium   # Update to webdriver - issues with window resize

reload(sys)
sys.setdefaultencoding("utf-8")	# Sets encoding

BASEURL = 'http://ec2.qa.nymetro.com/thecut/celebrity/'
BROWSERS = ('chrome', 'firefox', 'safari')	# IE must be run through WebDriver remote (which does not have good window resizing func)
TEST = "Celebrity Splash Page - QA - The Cut"

L = Logger.MainLogger(BASEURL, TEST)

S = cutSoup.Parser(BASEURL)
S.qa_celebrity_splash_feed()

CSS = open('../data/text/qa.celebritysplashfeed.css.txt', 'r').readlines()
FEED_DATA = pickle.load(open('../data/pickle/qa.celebritysplashfeed.data.p', 'rb'))

feed_keys = FEED_DATA.keys()
feed_values = FEED_DATA.values()

x = 0

"""
This is a test for the Cut Celebrity Splash Pages:
The DATA file is a pickle file generated by vultureSoup.Parser(), customized for this module.
IF ANY CHANGES TO THE MODULE HAPPEN, PLEASE ONLY CHANGE THE .TXT, .P and .JSON FILES IF YOU REALLY KNOW WHAT YOU ARE DOING!
"""	

#########################################################################
#########################################################################
	

class CelebritySplash(unittest.TestCase):

    def setUp(self):

        self.verificationErrors = []
        self.selenium = selenium("localhost", 4444, "*" + BROWSERS[x], BASEURL)
        self.selenium.start()
        print "TESTING www.thecut.com in " + BROWSERS[x]
	
	########################################################################
    
    def test_splash_feed(self):
        
        """
        Preliminary test for the presence of various elements in each article in the Celebrity/Fame feed.
        CSS selectors are in a .txt file, and this test makes sure each element exists on the page before proceeding.
        Failures will fail the whole test.  (No point in continuing if images and links aren't present, right?).
        The other tests are called from this function to avoid repetitive and unnecessary SetUp and TearDown of the browser.
        In addition, the other tests can be commented out and not run - easy to select which tests run.  None are dependent on 
        results from other tests.  Only test_splash_feed needs to be run for the sub-tests to run.
        
        PASSING CONDITIONS:  All elements are present on the page.
        FAILING CONDITIONS:  Any ONE element is not present on the page.
        """
	
        n = 0
        sel = self.selenium
        sel.open(BASEURL)
        sel.wait_for_page_to_load("50000")
        test = "Test A - Presence of elements via CSS"
        
        # Loops through the data in the CSS file asserting each element is on the page
        
        for each in CSS:

	    c = CSS[n].strip('\n')
            
            try:
                self.failUnless(sel.is_element_present("css=" + c))
                
            except AssertionError, e:
            	print "FAILURE " + c
            	self.verificationErrors.append(str(e))
                L.log(BROWSERS[x], test, "FAIL, ELEMENT NOT FOUND", c, exception=str(e))
            
            else:
                L.log(BROWSERS[x], test, "PASS, ELEMENT FOUND", c)
                
            n += 1
        
        self.b_showMore_test()		# Tests the "show more" button    	
        self.c_timestamp_test()		# Tests to make sure that all timestamps are appearing and valid/correct (data pulled using JSON)
        self.d_responsive_test()		# Tests the responsive design of the page
        self.e_clicky_test()		# Functional test - clicks on links and images to make sure they load the correct page
            
        ########################################################################
	    
    def b_showMore_test(self):
    	    
        """
        This test collects the number of images, timestamps, etc. present on the page at page load.
        Then, it clicks the "Show More" button and waits for the js to execute.
        Lastly, it re-counts the number of images, etc. and takes the difference in the two.
        The difference must be equal to the number of articles that load when clicking the button.  
        
        PASSING CONDITIONS:  The difference in css_count before clicking the button and after is strictly equal to 
                             the number of articles that appear after clicking the "Show More" button.
        FAILING CONDITIONS:  The difference in css_count is not equal to the number of articles that appear after
        		     clicking the "Show More" button.
        """
    	 
	sel = self.selenium
        test = "Test B - Show More button"
        print test
        
        images = sel.get_css_count("css=" + CSS[0])
        timestamp = sel.get_css_count("css=" + CSS[1])
	comments = sel.get_css_count("css=" + CSS[2])
        headers = sel.get_css_count("css=" + CSS[3])
	paragraphs = sel.get_css_count("css=" + CSS[4])
        
	sel.click("css=" + CSS[5])
	time.sleep(3)
	
	images2 = sel.get_css_count("css=" + CSS[0]) - images
	timestamp2 = sel.get_css_count("css=" + CSS[1]) - timestamp
	comments2 = sel.get_css_count("css=" + CSS[2]) - comments
        headers2 = sel.get_css_count("css=" + CSS[3]) - headers
        paragraphs2 = sel.get_css_count("css=" + CSS[4]) - paragraphs
        
        if ((images2 < 5) or (timestamp2 < 5) or (comments2 < 5) or (headers2 < 5) or (paragraphs2 < 5)):
            print "Missing articles!"
            L.log(BROWSERS[x], test, "FAIL, MISSING CONTENT AFTER CLICKING LOAD MORE", "Images: " + str(images2) + " Timestamp: " + str(timestamp2) + " Comments: " + str(comments2) + " Headers: " + str(headers2) + " Paragraphs: " + str(paragraphs2)) 
    
	else:
	    L.log(BROWSERS[x], test, "PASS, LOAD MORE WORKS OK", "None")
	    
	########################################################################    
   
    def c_timestamp_test(self):
    	    
    	"""
    	This test verifies that each article contains the correct timestamp.
    	The data is pulled from a JSON file in nymagSoup and added to the data dictionary in the pickle file.
    	This test will run even if failing conditions are met for any one article.
    	
    	PASSING CONDITIONS:  All articles have the correct timestamp.  
    	FAILING CONDITIONS:  If an article does not have a timestamp, the whole test will fail.
    	"""
     	     
        m = 0    
        sel = self.selenium
        test = "Test C - Timestamps"
        print test
        
	for each in feed_keys:
        
            blah = feed_values[m]
            json_time = blah[1]	
            
            try:
                sel.is_text_present(json_time)
            
    	    except Exception, e:
    	    	L.log(BROWSERS[x], test, "FAIL, CANNOT FIND TIMESTAMP FOR ARTICLE", feed_keys[m], exception=str(e))
        
	    else:
	        L.log(BROWSERS[x], test, "PASS, TIMESTAMPS FOUND", feed_keys[m].strip("^^"))
	    	    
	    m += 1
	    
        ########################################################################
        
    def d_responsive_test(self):
    	    
    	"""
    	This test resizes the browser window to test the feed for responsive design functionality.
    	The browser is first set to full screen for desktop, resized for tablet, then resized for mobile.
    	Image height/width, paragraph/excerpt position and link position (for the article header) are retrieved.
    	Element sizes and positions are then compared to ensure that they change with window sizes accordingly.
    	This test will run even if failing conditions are met for any one article.
    	
    	PASSING CONDITIONS:  For images: if desktop element size > tablet element size > mobile element size
    			     For excerpts/titles: if elements do not move further left on the page.
    	                     (elements should get smaller/move to the left as the window size shrinks)
    	FAILING CONDITIONS:  Elements do not shrink/move left when the browser is resized.
    	"""
    	   
        sel = self.selenium
        test = "Test D - Responsive Design"
        print test
        m = 0
        
        for each in feed_keys:
        	
            data = feed_values[m]
            image = data[0]
            
            if image is not None:
            	
		for w in range(0,3):
		    	    
		    if w == 0:
			sel.window_maximize()
			desktop_height = sel.get_element_height("//img[@src='" + image + "']")
			desktop_width = sel.get_element_width("//img[@src='" + image + "']")
			desktop_paragraph_loc = sel.get_element_position_left("//p[@class='excerpt']")
			desktop_title_loc = sel.get_element_position_left("//a[@href='" + feed_keys[m].strip("^^") + "']")
			  
		    elif w == 1:
			sel.get_eval("window.resizeTo(728, 1000);")
			tablet_height = sel.get_element_height("//img[@src='" + image + "']")
			tablet_width = width = sel.get_element_width("//img[@src='" + image + "']")
			tablet_paragraph_loc = sel.get_element_position_left("//p[@class='excerpt']")
			tablet_title_loc = sel.get_element_position_left("//a[@href='" + feed_keys[m].strip("^^") + "']")
			
		    elif w == 2:
			sel.get_eval("window.resizeTo(420, 600);")
			mobile_height = sel.get_element_height("//img[@src='" + image + "']")
			mobile_width = sel.get_element_width("//img[@src='" + image + "']")
			mobile_paragraph_loc = sel.get_element_position_left("//p[@class='excerpt']")
			mobile_title_loc = sel.get_element_position_left("//a[@href='" + feed_keys[m].strip("^^") + "']")
			    
		    w += 1
                
            	if ((desktop_height >= tablet_height) and (desktop_height >= mobile_height) and (tablet_height >= mobile_height)):
            	    L.log(BROWSERS[x], test, "PASS, IMAGE RESPONDS TO WINDOW RESIZE", image)
                
            	else:
            	    print "Resize image fails!", image
            	    L.log(BROWSERS[x], test, "FAIL, IMAGE DOES NOT RESPOND TO WINDOW RESIZE", image)
                    
            	if ((desktop_paragraph_loc >= mobile_paragraph_loc) and (tablet_paragraph_loc >= mobile_paragraph_loc)):
                    L.log(BROWSERS[x], test, "PASS, EXCERPT RESPONDS TO WINDOW RESIZE", "Excerpt for " + feed_keys[m])
                
            	else:
            	    print "Resize exceprt fails!", feed_keys[m]
            	    L.log(BROWSERS[x], test, "FAIL, EXCERPT DOES NOT RESPOND TO WINDOW RESIZE", "Excerpt for " + feed_keys[m])
                
            	if ((desktop_title_loc >= mobile_title_loc) and (tablet_title_loc >= mobile_title_loc)):
            	    L.log(BROWSERS[x], test, "PASS, ARTICLE TITLE RESPONDS TO WINDOW RESIZE", "Title for " + feed_keys[m])
                
            	else:
            	    L.log(BROWSERS[x], test, "FAIL, ARTICLE TITLE DOES NOT RESPOND TO WINDOW RESIZE", "Title for " + feed_keys[m])
            
	    else:
            	print "NO IMAGE for URL " + feed_keys[m]
	        L.log(BROWSERS[x], test, "FAIL, NO IMAGE FOR URL!", feed_keys[m])
	        
	    m += 1
            
        sel.get_eval("window.resizeTo(1200, 1000);")    
            
    	########################################################################

    def e_clicky_test(self):
    	    
        """
        This test makes Selenium do some real work - functionality of links and images is tested.
        All links are clicked on and tested to make sure the page loads, the title does not have "not found" in it, and
        the title is stored in a variable.
        All images are clicked on and tested to make sure the page loads, the title does not have "not found" in it, and
        the title is compared to the previous link's title to make sure the correct article loads (in other words, to make
        sure that the image is associated with the correct article.
        This test will not fail when one error is encountered - the test will continue to check all links and images regardless
        of a failure, unless an exception is thrown that breaks the test itself.
        
        PASSING CONDITIONS:  All pages load, no pages have 404/not found errors, and the link and image direct the user to
        		     the correct page.
        FAILING CONDITIONS:  Any of the links/images do not load or are not on the page, any of the links/images return pages with 404/not found errors,
        		     any of the link/image pairs contain mismatched titles, indicating that either an article link is broken
        		     or a link with an associated image is not correctly paired to the article title.
        """
    	
    	m = 0 
        sel = self.selenium
        test = "Test E - Functional test for urls"
        print test
        
        for each in feed_keys:
		
	    d = feed_keys[m]
	    d = d.strip('^^')
	    data_values = feed_values[m]
	    c = data_values[0]
	    
	    try:
                sel.click("//a[@href='" + d + "']")
                sel.wait_for_page_to_load("50000")
                
	    except Exception, e:
		print "FAILURE " + d, " does not load"
		L.log(BROWSERS[x], test, "FAIL, PAGE DOES NOT LOAD", d, exception=str(e))
		
	    else:
	    	try:
	    	    title = sel.get_title()
	    
                except Exception, e:
                    print "FAILURE " + d, " cannot get title"
                    L.log(BROWSERS[x], test, "FAIL, CANNOT GET TITLE", d, exception=str(e))
	    	
		else:
		    if re.search("Not Found", title, re.I):
		    	print "FAILURE " + d, " Page Not Found!"
		        L.log(BROWSERS[x], test, "FAIL, 404 ERROR!", "Page: " + d + " Title: " + title)
	      		
	      	    else:
	    		L.log(BROWSERS[x], test, "PASS, PAGE LOADS", "Page: " + d + " Title: " + title)
		
                sel.go_back()
	        sel.wait_for_page_to_load("50000")
	        
	# Second, make sure each image can be clicked on and that the page loads  
	
	    if c is not None:
	        try:
                    sel.click("//img[@src='" + c + "']")
                    sel.wait_for_page_to_load("50000")
                
	        except Exception, e:
		    print "FAILURE " + c, " does not load"
		    L.log(BROWSERS[x], test, "FAIL, IMAGE DOES NOT LOAD", c, exception=str(e))
		
	        else:
	            try:
	    	        img_title = sel.get_title()
                    except Exception, e:
                    	print "FAILURE " + c, " cannot get title"
                        L.log(BROWSERS[x], test, "FAIL, CANNOT GET TITLE", d, exception=str(e))
	    	
		    else:
		        if re.search("Not Found", img_title, re.I):
		            print "FAILURE " + c, " Page Not Found!"
		            L.log(BROWSERS[x], test, "FAIL, 404 Error!", "Page: " + d + " Title: " + title)
	      		
	      	        elif not re.search(img_title, title, re.I):
	      	            print "FAILURE " + c, " URL associated with image (href, not src) does not match article URL"
	      	            L.log(BROWSERS[x], test, "FAIL, Mismatched titles for image link and permalink", "Page: " + d + " Article Link Title: " + title, "Image Link Title: " + img_title)
	            
	    		else:
	    		    L.log(BROWSERS[x], test, "PASS, ARTICLE TITLE URL MATCHES ASSOCIATED IMAGE URL", c)
		    
 		    sel.go_back()
	            sel.wait_for_page_to_load("50000")
	            
	    else:
	    	print "NO IMAGE for URL " + d
	        L.log(BROWSERS[x], test, "FAIL, NO IMAGE FOR URL!", "URL: " + d)
	        
	    m += 1

        ########################################################################

    def tearDown(self):

        self.selenium.stop()
        self.assertEqual([], self.verificationErrors)

#########################################################################
#########################################################################

for each in BROWSERS:

    suite = unittest.TestLoader().loadTestsFromTestCase(CelebritySplash)
    unittest.TextTestRunner(verbosity=2).run(suite)
    x += 1
L.save()