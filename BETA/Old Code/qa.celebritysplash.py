#! /usr/bin/python

import unittest
import time, datetime
import re
import pickle
import json
from pprint import pprint
import Logger			# Logging module (for test results, outputs results to a .txt file)
import cutSoup     		# BeautifulSoup page scraper collects relevant data from qa.nymetro
from selenium import selenium   # Update to WebDriver 

BASEURL = 'http://ec2.qa.nymetro.com/thecut/celebrity/#'
BROWSERS = ('chrome', 'firefox', 'safari')
TEST = "Celebrity Splash Page - QA - The Cut"

L = Logger.MainLogger("http://ec2.qa.nymetro.com/thecut/celebrity/#", TEST)

S = cutSoup.Parser('http://ec2.qa.nymetro.com/thecut/celebrity/#')
S.qa_celebrity_splash_feed()
S.qa_celebrity_splash_lede()

CSS = open('../data/text/qa.celebritysplash.css.txt', 'r').readlines()
FEED_DATA = pickle.load(open('../data/pickle/qa.celebritysplashfeed.data.p', 'rb'))
LEDE_DATA = pickle.load(open('../data/pickle/qa.celebritysplashlede.data.p', 'rb'))
JSON = open('../data/json/cut.json').read()

feed_keys = FEED_DATA.keys()
feed_values = FEED_DATA.values()
lede_keys = LEDE_DATA.keys()
lede_values = LEDE_DATA.values()
json_keys = JSON.keys()
json_values = JSON.values()

x = 0

"""
This is a test for the Cut Celebrity Splash Pages:

Test 'a' is a 'presence' test:  Do the elements (via CSS selectors in the CSS file) appear on the page and in the correct spot?
Test 'b' is a 'content' test:  Do the elements contain the relevant data?  
Test 'c' is a 'functional' test:  Does the module work?  Do links work?  Do the right pages load?  

The DATA file is a pickle file generated by vultureSoup.Parser(), customized for this module.

IF ANY CHANGES TO THE MODULE HAPPEN, PLEASE ONLY CHANGE THE .TXT, .P and .JSON FILES IF YOU REALLY KNOW WHAT YOU ARE DOING!
"""	

#########################################################################
#########################################################################
	

class CelebritySplash(unittest.TestCase):

    def setUp(self):

        self.verificationErrors = []
        self.selenium = selenium("localhost", 4444, "*" + BROWSERS[x], BASEURL)
        self.selenium.start()
        print "TESTING www.thecut.com in " + BROWSERS[x]
	
	########################################################################
    
    def test_a(self):
        
        # Tests for the presence of elements in the module using CSS locators
        # This test is an 'assert' test: if any element is not present, the test fails
	
        n = 0
        sel = self.selenium
        sel.open("http://ec2.qa.nymetro.com/thecut/celebrity/#")
        sel.wait_for_page_to_load("50000")
        
        # Loops through the data in the CSS file asserting each element is on the page
        
        for each in CSS:

	    c = CSS[n].strip('\n')
            
            try:
                self.failUnless(sel.is_element_present("css=" + c))
                
            except AssertionError, e:
            	print "FAILURE " + c
            	self.verificationErrors.append(str(e))
                L.log(BROWSERS[x], TEST, "FAIL, ELEMENT NOT FOUND", str(e) + c)
            
            else:
                L.log(BROWSERS[x], TEST, "PASS, ELEMENT FOUND", c)
                
            n += 1
    
        self.c()
            
        ########################################################################
	    
    def test_b(self):
    	    
        # Tests for the correct content within the module
        # This is a 'verify' test, it will not fail the whole test if one item fails
    	 
    	m = 0
	sel = self.selenium
        sel.open("http://ec2.qa.nymetro.com/thecut/celebrity/#")
        sel.wait_for_page_to_load("50000")
        
        # Gets the link text for each link in DATA
        # Comments
        # Opens page
        # Gets the page's title and checks that the link text is in the title (correct page loads)
        # Checks page for tags?
        
	pass
        
        
        ########################################################################

    def c(self):
    	    
    # Tests for the module's functionality
    # Clicks on each link based on its address (href attribute)
    # Makes sure the page loads
    	
    	m = n = 0 
        sel = self.selenium
        sel.open("http://ec2.qa.nymetro.com/thecut/celebrity/#")
        sel.wait_for_page_to_load("50000")
        
        images = sel.get_css_count("css=" + CSS[3])
	timestamp = sel.get_css_count("css=" + CSS[4])
	comments = sel.get_css_count("css=" + CSS[5])
        headers = sel.get_css_count("css=" + CSS[6])
	paragraphs = sel.get_css_count("css=" + CSS[7])

        # If any of the above are not equal to the length of data.keys, error
        
        # First, make sure each link can be clicked on and that the page loads
        
        for each in feed_keys:
		
	    d = feed_keys[m]
	    d = d.strip('^^')
	    c = feed_values[m]
	    
	    try:
                sel.click("//a[@href='" + d + "']")
                sel.wait_for_page_to_load("50000")
                
	    except Exception, e:
		print "FAILURE " + d, " does not load"
		L.log(BROWSERS[x], TEST, "FAIL, PAGE DOES NOT LOAD", str(e) + " " + d)
		
	    else:
	    	L.log(BROWSERS[x], TEST, "PASS, Page loads", d)
                sel.go_back()
                sel.wait_for_page_to_load("50000")
	        
	# Second, make sure each image can be clicked on and that the page loads           
            if c is not None:
                try:
                    sel.click("//img[@src='" + c + "']")
                    sel.wait_for_page_to_load("50000")
                    
                except Exception, e:
                    print "FAILURE " + c, " does not load"
                    L.log(BROWSERS[x], TEST, "FAIL, IMAGE DOES NOT LOAD", str(e) + c)
            
                else:
                    L.log(BROWSERS[x], TEST, "PASS, Page loads", c)
                    sel.go_back()
                    sel.wait_for_page_to_load("50000")
	            
	    m += 1

        for each in lede_keys:
		
	    d = lede_keys[n]
	    
	    d = d.strip('^^')
	    c = lede_values[n]
	    
	    try:
                sel.click("//a[@href='" + d + "']")
                sel.wait_for_page_to_load("50000")
                
	    except Exception, e:
		print "FAILURE " + d, " does not load"
		L.log(BROWSERS[x], TEST, "FAIL, PAGE DOES NOT LOAD", str(e) + d)
		
	    else:
	    	L.log(BROWSERS[x], TEST, "PASS, Page loads", d)
		sel.go_back()
	        sel.wait_for_page_to_load("50000")
	        
	# Second, make sure each image can be clicked on and that the page loads           
            if c is not None:
	        try:
                    sel.click("//img[@src='" + c + "']")
                    sel.wait_for_page_to_load("50000")
                
	        except Exception, e:
		    print "FAILURE " + c, " does not load"
		    L.log(BROWSERS[x], TEST, "FAIL, IMAGE DOES NOT LOAD", str(e) + c)
		
	        else:
	            L.log(BROWSERS[x], TEST, "PASS, Page loads", c)
		    sel.go_back()
	            sel.wait_for_page_to_load("50000")
	            
	        n += 1
	    
	    sel.click("css=" + CSS[8])
	    time.sleep(10)
	    
        images = sel.get_css_count("css=" + CSS[3])
	timestamp = sel.get_css_count("css=" + CSS[4])
	comments = sel.get_css_count("css=" + CSS[5])
        headers = sel.get_css_count("css=" + CSS[6])
        paragraphs = sel.get_css_count("css=" + CSS[7])
            
        ########################################################################

    def tearDown(self):

        self.selenium.stop()
        self.assertEqual([], self.verificationErrors)

#########################################################################
#########################################################################

for each in BROWSERS:

    suite = unittest.TestLoader().loadTestsFromTestCase(CelebritySplash)
    unittest.TextTestRunner(verbosity=2).run(suite)
    x += 1
L.save()